## Node Failures

### Data Node Failures
situations where one or more DataNodes become unavailable or crash leading to unavailability of data

1. Permanent Data Node Failure
2. Temporary Data Node Failure

### How are data node failures handled by hadoop ?
How HDFS Handles DataNode Failures:

Replication: Each data block is replicated (default replication factor = 3) across multiple DataNodes. If a DataNode fails, the block's replica on another DataNode can still be accessed.
Re-replication: The NameNode detects the failure and triggers re-replication of the lost data blocks to healthy DataNodes.
Automatic Recovery: The system automatically recovers from DataNode failures by using the replicated copies and maintaining the integrity of the data.
Key Points:
Data redundancy through replication ensures that data is not lost.
Fault tolerance allows the system to recover from failures and continue operations without data loss.


